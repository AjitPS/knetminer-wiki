_(preview/beta feature)_

It is now possible to spin up a new dedicated **Knetminer** instance with a custom **OXL** file using **Docker**, or to the cloud using **AWS** ElasticBeanStalk. Follow the simple instructions below to see how.

## Before starting:

1. You will need to have your OXL file, your SemanticMotifs.txt, and any other files required by the configuration (see below) accessible via an HTTP URL, i.e. saved on a web server or in an **S3** bucket. They must be _publicly_ accessible for the duration of the deployment but can be hidden or deleted once deployment is complete
2. If using Docker, you will need to **install** Docker locally
3. If using AWS ElasticBeanStalk, you will need an AWS account. The instructions below assume you will deploy KnetMiner using the ElasticBeanStalk command-line interface (**eb-cli**), but you can also achieve the same results through the AWS console web interface

***

## To install using Docker:

1. Into an empty folder download the [Dockerfile](https://raw.githubusercontent.com/Rothamsted/knetminer/20181001_autodeploy/common/quickstart/Dockerfile)
2. Edit the downloaded Dockerfile and in the first ENV section at the top update the settings:
   1. Note that this includes the branch of the KnetMiner GitHub repository to use, and in most circumstances this should be the same branch that you got the `Dockerfile` from in the first place (`20181001_autodeploy` in this example) otherwise behaviour could be unpredictable
   2. The defaults shown in the file will also work if you just want to try it and see - the example URLs it references are in a public S3 bucket in the KnetMiner AWS account
3. On the command line inside the folder where you downloaded the Dockerfile, type:
```
docker image build --squash -t knetminer .
docker run -p8080:8080 -it --rm knetminer
```
4. After waiting about ten minutes for the previous step to complete youâ€™ll be able to access KnetMiner at `http://localhost:8080/client/`

***

## To install using AWS ElasticBeanStalk:
1. Into an empty folder download two files:
   1. [Dockerfile](https://raw.githubusercontent.com/Rothamsted/knetminer/20181001_autodeploy/common/quickstart/Dockerfile)
   2. [Dockerrun.aws.json](https://raw.githubusercontent.com/Rothamsted/knetminer/20181001_autodeploy/common/quickstart/Dockerrun.aws.json)
2. Edit the downloaded Dockerfile and in the first ENV section at the top update the settings
   1. Note that this includes the branch of the knetminer Git repository to use, and in most circumstances this should be the same branch that you got the Dockerfile from in the first place (`20181001_autodeploy` in this example) otherwise behaviour could be unpredictable
   2. The defaults shown in the file will also work if you just want to try it and see - the example URLs it references are in a public S3 bucket in the Knetminer AWS account
3. If you are using the AWS ElasticBeanStalk web interface, zip the folder containing the two files into a single zip archive, then go to the AWS console to upload and deploy it (the type is Generic->Docker, and your source bundle is the zip file you just created)
4. If you are using the ElasticBeanStalk command-line method instead, then from within the folder containing the two files type the following commands and follow any instructions they give you:
```
eb init
eb create
```
5. After waiting about ten minutes for it to start up, scan the output of the commands for the details of the load balancer it has created, or otherwise go to the AWS console in your web browser and look for the load balancer details there. Make a note of the load balancer's hostname (public DNS)
6. You can now access KnetMiner at: `http://\<your-load-balancer-hostname\>/client/`

***

## **_(new)_** - To install using Docker on a VM (e.g., CentOS) and with locally stored data/files:

1. Clone **KnetMiner** code on the VM in a new folder (e.g., in _/home/usern/foo-bar/_), e.g, clone latest branch from GitHub via: `git clone --single-branch -b 20181001_rhlastweek https://github.com/Rothamsted/knetminer/`
2. For a particular species, e.g., Arabidopsis, ensure the latest files (semantic motifs, image, example queries) are in the correct **species/** folder locally, e.g., at `https://github.com/Rothamsted/knetminer/tree/20181001_rhlastweek/arabidopsis`
3. Upload your latest species **OXL** into this folder as well.
4. Run `build-docker-dev.sh` or equivalent in this folder. This takes all the **local data** in this folder and invokes `https://github.com/Rothamsted/knetminer/blob/20181001_rhlastweek/common/quickstart/Dockerfile-dev` which builds a Docker image, e.g, **knetminer-arabidopsis-dev** using a specific **OXL** and on a specific **port**.
5. Once built, use `docker run -p8080:8080 -it --rm knetminer-arabidopsis-dev` to run it on `localhost:8080` (change port number as defined in `build-docker-dev.sh`). **Note**: when container is starting up, press Ctrl+P and Ctrl+Q to exit to terminal while keeping interactive container running.
6. Access the deployed GUI on `localhost:8080/client` and API via `localhost:8080/ws/`.
7. _Debugging:_ Check **logs** inside the running container via `docker exec -it containerID /bin/sh`. You will be at `/root` which has: `knetminer/common/` code and `data.oxl` while Tomcat logs will be at `/usr/local/tomcat/logs/`.

## Docker Tidy-up on local VM:
1. To view all **images** on a VM, use `docker images`
2. To view all **containers** on a VM, use `docker ps`
3. To **stop** a running container, use `docker stop containerID` (`containerID` can be listed first via `docker ps`).
4. To delete an old image, use `docker image rm imageID` (`imageID` can be listed first via `docker images`). 
5. To delete an old container, use `docker container rm containerID`
6. To remove "_dangling images_" (after image deletion), use `docker image prune`
7. To clean-up a VM, **use** `docker system prune` and then enter 'y' (removes all stopped containers, dangling images and unused volumes to free up max. space).
8. further info. at: [linux-Docker-cleanup docs](https://linuxize.com/post/how-to-remove-docker-images-containers-volumes-and-networks/)
